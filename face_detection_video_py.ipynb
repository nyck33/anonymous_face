{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_detection_video.py",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyck33/anonymous_face/blob/master/face_detection_video_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZbxUBdPHjlD",
        "colab_type": "code",
        "outputId": "a637f538-8e17-4cb4-fd81-321bc5350f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "#install cvlib\n",
        "\n",
        "!pip3 install cvlib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cvlib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/b0/310c483b2a8aa269e60590627880ee5f7c817e8284d845ba26f6aef77965/cvlib-0.2.1.tar.gz (10.0MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cvlib) (1.16.4)\n",
            "Collecting progressbar (from cvlib)\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cvlib) (2.21.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from cvlib) (4.3.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from cvlib) (2.2.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cvlib) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cvlib) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cvlib) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cvlib) (2.8)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->cvlib) (0.46)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->cvlib) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->cvlib) (1.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->cvlib) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->cvlib) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->cvlib) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->cvlib) (1.0.8)\n",
            "Building wheels for collected packages: cvlib, progressbar\n",
            "  Building wheel for cvlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/ea/9b/4719777f32dcdd50c72cf4c6b3fa189265b2c59437c0829a88\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
            "Successfully built cvlib progressbar\n",
            "Installing collected packages: progressbar, cvlib\n",
            "Successfully installed cvlib-0.2.1 progressbar-2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwpMuAbvHd4s",
        "colab_type": "code",
        "outputId": "50c15791-f443-4fba-de7c-d543615dc206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# author: Arun Ponnusamy\n",
        "# website: https://www.arunponnusamy.com\n",
        "\n",
        "# face detection example\n",
        "# usage: python face_detection.py <input_image>\n",
        "\n",
        "# import necessary packages\n",
        "import cvlib as cv\n",
        "import sys\n",
        "import cv2\n",
        "import os \n",
        "import argparse\n",
        "\n",
        "\n",
        "vid_name = \"video.mp4\"\n",
        "video = cv2.VideoCapture(vid_name)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "#get vid info\n",
        "vidw = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "vidh = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "output_video_path = 'video.avi'\n",
        "\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (int(vidw), int(vidh)))\n",
        "\n",
        "#success, image = vidcap.read()\n",
        "count = 0\n",
        "\n",
        "# read input image\n",
        "#if sys.argv[1]:\n",
        "#    image = cv2.imread(sys.argv[1])\n",
        "#else:\n",
        "success, image = video.read()\n",
        "\n",
        "if not success:\n",
        "    print(\"Cannot read video file\")\n",
        "    sys.exit()\n",
        "\n",
        "while success:\n",
        "    # apply face detection\n",
        "    faces, confidences = cv.detect_face(image)\n",
        "\n",
        "    #print(faces)\n",
        "    #print(confidences)\n",
        "\n",
        "    # loop through detected faces\n",
        "    for face,conf in zip(faces,confidences):\n",
        "\n",
        "        (startX,startY) = face[0],face[1]\n",
        "        (endX,endY) = face[2],face[3]\n",
        "\n",
        "        # draw rectangle over face\n",
        "        cv2.rectangle(image, (startX,startY), (endX,endY), (0,255,0), 2)\n",
        "\n",
        "    # display output\n",
        "    # press any key to close window           \n",
        "    #cv2.imshow(\"face_detection\", image)\n",
        "    #cv2.waitKey()\n",
        "\n",
        "    # save output\n",
        "    #cv2.imwrite(\"face_detection/frame%d.jpg\", %count, image)\n",
        "\n",
        "    #save output vid\n",
        "    out.write(image)\n",
        "\n",
        "    success, image = video.read()\n",
        "    if not success:\n",
        "        pirnt('Cannot read video file')\n",
        "        sys.exit()\n",
        "\n",
        "# release resources\n",
        "video.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8e393d95bfd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# apply face detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#print(faces)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cvlib/face_detection.py\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(image, threshold)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# apply face detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}